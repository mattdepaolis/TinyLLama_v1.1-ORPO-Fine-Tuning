{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0230991b",
   "metadata": {},
   "source": [
    "# Fine-tuning via Chat Fine-tuning using ORPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a73f98",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d7c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HUB_ENABLEHF_TRANSFER=True\n"
     ]
    }
   ],
   "source": [
    "%env HF_HUB_ENABLEHF_TRANSFER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88cce428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_API_KEY=738485c7fc8f7262c37f7daab2a829956acea924\n",
      "env: HUGGINGFACE_TOKEN=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\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install wandb -q -U\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92eb431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --upgrade pip\n",
    "#!pip install -U -q transformers\n",
    "#!pip install -U -q bitsandbytes\n",
    "#!pip install -U -q peft\n",
    "#!pip install -U -q accelerate\n",
    "#!pip install -U -q scipy\n",
    "#!pip install -U -q trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06e87e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = ''\n",
    "\n",
    "model_id = \"TinyLlama/TinyLlama_v1.1\"\n",
    "new_model = \"llmat/TinyLlama-1.1B-ORPO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326db85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## monitor gpu activity\n",
    "# watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead4128",
   "metadata": {},
   "source": [
    "## Load the Model and Tokenizer for LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8404ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Define the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map='auto',\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "# Define the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_fast=True,\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=cache_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972937fd",
   "metadata": {},
   "source": [
    "## Loading Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3676421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no parameters overflowing onto cpu (meta).\n",
    "for n, p in model.named_parameters():\n",
    "    if p.device.type=='meta':\n",
    "        print(f\"{n} is on meta!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb33c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.config.max_position_embeddings)\n",
    "print(model.config.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e737e",
   "metadata": {},
   "source": [
    "# Prepare for LoRA fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc1dbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainablöe parameters in the model and lists which parameters\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    non_trainable_params = 0\n",
    "    all_params = 0\n",
    "\n",
    "    print(\"Trainable Parameters\")\n",
    "    for name, param in model.named_parameters():\n",
    "        all_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "            print(f\" {name}\")\n",
    "        else:\n",
    "            non_trainable_params += param.numel()\n",
    "\n",
    "    print(\"\\nNon-Trainable Parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            print(f\" {name}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nSummary:\\n Trainable params: {trainable_params}\\n Non-Trainable params: {non_trainable_params}\\n All Parameters: {all_params}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96adb383",
   "metadata": {},
   "source": [
    "# Standard LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f96b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): LlamaForCausalLM(\n",
      "          (model): LlamaModel(\n",
      "            (embed_tokens): Embedding(32000, 2048)\n",
      "            (layers): ModuleList(\n",
      "              (0-21): 22 x LlamaDecoderLayer(\n",
      "                (self_attn): LlamaFlashAttention2(\n",
      "                  (q_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=256, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=256, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (rotary_emb): LlamaRotaryEmbedding()\n",
      "                )\n",
      "                (mlp): LlamaMLP(\n",
      "                  (gate_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=5632, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (up_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=5632, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (down_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=5632, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=5632, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (act_fn): SiLU()\n",
      "                )\n",
      "                (input_layernorm): LlamaRMSNorm()\n",
      "                (post_attention_layernorm): LlamaRMSNorm()\n",
      "              )\n",
      "            )\n",
      "            (norm): LlamaRMSNorm()\n",
      "          )\n",
      "          (lm_head): lora.Linear(\n",
      "            (base_layer): Linear(in_features=2048, out_features=32000, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=8, out_features=32000, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d4313fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable() # Comment this in to save VRAM\n",
    "\n",
    "# Only use the line below if you are using quantization\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig( # matching the Llama recipe\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        # \"self_attn.rotary_emb.inv_freq\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\", # Language model head - best to set this trainable if chat fine-tuning\n",
    "        #\"lora_magnitude_vector\", # required for DoRA\n",
    "        #\"input_layernorm.weight\", #can't be lora fine-tuned as it's not a linear layer\n",
    "        #\"post_attention_layernorm.weights, #can't be lora fine-tuned as it's not a linear layer\n",
    "        #\"model.norm.weight\", #can't be lora fine-tuned as it's not a linear layer\n",
    "    ],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Convert the model to a PEFT model\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efec0e5",
   "metadata": {},
   "source": [
    "# Set up Tokenizer and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "118ded20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama_v1.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "32000\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05bba153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token)\n",
    "print(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfbdf70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% if messages[0]['role'] != 'assistant' %}{{ bos_token }}{% endif %}{% for message in messages %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token }}{% endif %}{% endfor %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b39f693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] write a quick sort algorithm in python. [/INST]here you are.</s>[INST] great. [/INST]\n"
     ]
    }
   ],
   "source": [
    "# OPTIONALLY SET THE CHAT TEMPLATE MANUALLY\n",
    "# Llama/Mistral template. NOTE: This is a special chat template that includes a check to add a beginning-of-sequence token (bos_token) if the first message in the conversation is not from the assistant. This is done to ensure that the conversation starts correctly depending on the initial message role.\n",
    "# This is done because we are separatly format the chosen and rejected responses. When we do that there is not going to be a user message at the beginning and do not want to add an extra bos_token before the response\n",
    "tokenizer.chat_template = \"\"\"{% if messages[0]['role'] != 'assistant' %}{{ bos_token }}{% endif %}{% for message in messages %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token }}{% endif %}{% endfor %}\n",
    "\"\"\"\n",
    "\n",
    "# Define the messages\n",
    "messages = [\n",
    "    {'role': 'user', 'content': 'write a quick sort algorithm in python.'},\n",
    "    {'role': 'assistant', 'content': 'here you are.'},\n",
    "    {'role': 'user', 'content': 'great.'},\n",
    "]\n",
    "\n",
    "# Apply the chat template to the messages\n",
    "inputs = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Print the inputs\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "165a9321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> token is in the tokenizer. Using <unk> for pad\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary of tokens to check for padding, with their corresponding print messages\n",
    "tokens_to_check = {\n",
    "    '<pad>': '<pad> token is in the tokenizer. Using <pad> for pad',\n",
    "    '<|pad|>': '<|pad|> token is in the tokenizer. Using <|pad|> for pad',\n",
    "    '<unk>': '<unk> token is in the tokenizer. Using <unk> for pad'\n",
    "}\n",
    "\n",
    "# Iterate over the dictionary of tokens\n",
    "for token, message in tokens_to_check.items():\n",
    "    # Check if the token is in the tokenizer's vocabulary\n",
    "    if token in tokenizer.get_vocab():\n",
    "        # Print the corresponding message for the token\n",
    "        print(message)\n",
    "        # Set the pad token for the tokenizer\n",
    "        tokenizer.pad_token = token\n",
    "        # Break out of the loop since we've found a suitable token\n",
    "        break\n",
    "# If we've checked all tokens and none of them are in the vocabulary\n",
    "else:\n",
    "    # Print a message indicating that the EOS token is used for padding\n",
    "    print(f'Using EOS token, {tokenizer.eos_token}, for padding')\n",
    "    # Set the pad token to the EOS token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f9e3eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer pad token ID: 0\n",
      "Model pad token ID: 0\n",
      "Model config pad token ID: 0\n",
      "Number of tokens now in tokenizer: 32000\n"
     ]
    }
   ],
   "source": [
    "# Update the pad token ID in the model and its config\n",
    "model.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Verify that the pad token IDs are equal\n",
    "assert model.pad_token_id == tokenizer.pad_token_id, \"The model's pad token IDs are not equal\"\n",
    "\n",
    "# Print the pad token IDs for the tokenizer, model, and model config\n",
    "print('Tokenizer pad token ID:', tokenizer.pad_token_id)\n",
    "print('Model pad token ID:', model.pad_token_id)\n",
    "print('Model config pad token ID:', model.config.pad_token_id)\n",
    "\n",
    "# Print the number of tokens in the tokenizer's vocabulary\n",
    "print('Number of tokens now in tokenizer:', tokenizer.vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebc4a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens map: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}\n",
      "All special tokens: ['<s>', '</s>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "print('Special tokens map:', tokenizer.special_tokens_map)\n",
    "print('All special tokens:', tokenizer.all_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b87dc073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama_v1.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1cdf6",
   "metadata": {},
   "source": [
    "# Set embed and norm layers to trainable (recommended for chat fine-tuning if you are changing the template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fc280e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): PeftModelForCausalLM(\n",
      "          (base_model): LoraModel(\n",
      "            (model): LlamaForCausalLM(\n",
      "              (model): LlamaModel(\n",
      "                (embed_tokens): Embedding(32000, 2048)\n",
      "                (layers): ModuleList(\n",
      "                  (0-21): 22 x LlamaDecoderLayer(\n",
      "                    (self_attn): LlamaFlashAttention2(\n",
      "                      (q_proj): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=2048, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (k_proj): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=256, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (v_proj): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=256, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (o_proj): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=2048, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (rotary_emb): LlamaRotaryEmbedding()\n",
      "                    )\n",
      "                    (mlp): LlamaMLP(\n",
      "                      (gate_proj): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=5632, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (up_proj): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=5632, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (down_proj): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=5632, out_features=2048, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=5632, out_features=8, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=8, out_features=2048, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (act_fn): SiLU()\n",
      "                    )\n",
      "                    (input_layernorm): LlamaRMSNorm()\n",
      "                    (post_attention_layernorm): LlamaRMSNorm()\n",
      "                  )\n",
      "                )\n",
      "                (norm): LlamaRMSNorm()\n",
      "              )\n",
      "              (lm_head): lora.Linear(\n",
      "                (base_layer): Linear(in_features=2048, out_features=32000, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=32000, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "feec65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold the names of the trainable parameters\n",
    "trainable_params_names = ['embed_tokens', 'input_layernorm', 'post_attention_layernorm', 'norm']\n",
    "\n",
    "# Set modules to be trainable\n",
    "for n, p in model.named_parameters():\n",
    "    if any(k in n for k in trainable_params_names):\n",
    "        p.requires_grad_(True)\n",
    "    else:\n",
    "        p.requires_grad_(False) # Optional: Set the rest to be trainable\n",
    "\n",
    "# Make a dictionary of trainable parameters\n",
    "trainable_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "# Convert trainable_params to state_dict format\n",
    "trainable_params_state_dict = {n: p.data for n, p in trainable_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84a21879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters\n",
      " base_model.model.base_model.model.base_model.model.model.embed_tokens.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.input_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.post_attention_layernorm.weight\n",
      " base_model.model.base_model.model.base_model.model.model.norm.weight\n",
      "\n",
      "Non-Trainable Parameters:\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight\n",
      " base_model.model.base_model.model.base_model.model.lm_head.base_layer.weight\n",
      " base_model.model.base_model.model.base_model.model.lm_head.lora_A.default.weight\n",
      " base_model.model.base_model.model.base_model.model.lm_head.lora_B.default.weight\n",
      "\n",
      "Summary:\n",
      " Trainable params: 65628160\n",
      " Non-Trainable params: 1041000448\n",
      " All Parameters: 1106628608\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c1e65",
   "metadata": {},
   "source": [
    "# Set up Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9cc669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import gc # import Python's garbage collection module\n",
    "\n",
    "# Define a stream\n",
    "def stream(user_prompt, model_type, tokenizer, checkpoint=''):\n",
    "    if model_type == 'base':\n",
    "        eval_model = model\n",
    "    elif model_type == 'fine-tuned':\n",
    "        eval_model = PeftModel.from_pretrained(model, checkpoint)\n",
    "        eval_model = eval_model.to('cuda')\n",
    "\n",
    "        for n, p in eval_model.named_parameters():\n",
    "            if p.device.type == 'cpu':\n",
    "                print(f'{n} is on cpu!')\n",
    "    \n",
    "    else:\n",
    "        print(\"You must set the model_type to base or fine-tuned\")\n",
    "        exit()\n",
    "    \n",
    "    print(f'Proceeding to inference with peft adapters from {checkpoint}')\n",
    "    \n",
    "    eval_model.config.use_cache = True\n",
    "\n",
    "    messages = [\n",
    "        { 'role': 'user', 'content': f\"{user_prompt.strip()}\"},\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer([inputs], return_tensors='pt', add_special_tokens=False).to('cuda')\n",
    "\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        del inputs[\"token_type_ids\"]\n",
    "    \n",
    "    streamer = TextStreamer(tokenizer)\n",
    "    \n",
    "    print(f'eval_model is on: {next(eval_model.parameters()).device}') # Debug line\n",
    "    print(f'input_ids are on: {inputs[\"input_ids\"].device}') # Debug line\n",
    "\n",
    "    # Despite returning the usal output, the streamer will also print the generated \n",
    "    #_ = eval_model.generate(**inputs, streamer=streamer, max_new_tokens=250, do_s)\n",
    "    _ = eval_model.generate(**inputs, streamer=streamer, max_new_tokens=250, do_sample=True)\n",
    "    \n",
    "    # Clear GPU cache and run garbage collection\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "def evaluation(model_type, checkpoint=''):\n",
    "    questions = [\n",
    "        \"What is one plus one?\",\n",
    "        \"Give me some python code to add the first five Fibonacci numbers.\",\n",
    "    ]\n",
    "    \n",
    "    answers = [\n",
    "        \"Two.\",\n",
    "        \"...\",\n",
    "    ]\n",
    "    \n",
    "    for question , answer in zip(questions, answers):\n",
    "        stream(question, model_type, tokenizer, checkpoint)\n",
    "        print('\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c60e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"_name_or_path\": \"TinyLlama/TinyLlama_v1.1\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b576b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 2048,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7502c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding to inference with peft adapters from LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama_v1.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<s> [INST] What is one plus one? [/INST]\") \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"  \" \" \" \" \"  \" \"  \"  \" \" \" \"  \"  \" \" \" \" \" …\" \" \" \" \" … \" \" … \" \". \" \" \" … \". \" \". \" \" \". \" A…\" \" \" \". \" \", \" A\". \"\". \" \"\". \" To A\". \" To A\". \" A …\" A\". \" A …\". To \"\". A…… A\". A…to A!\". A… to A!… A!\". A… to A!\". A… to A!\". A… to A!\". A… a! to a!… A!… A!!!\". A… A! to… A! to\" A!… A!!! A!!!\". A… A! A!!! A!!! A!!!!!!\". A… A!\". A… A to  A A to!… a\" a\" a\"a\"a\"a\" a\" a\"a\"a\" a\" a\"a\" a\"a\" a\"a\" a\" a\"a\" a\n",
      "\n",
      "\n",
      "\n",
      "Proceeding to inference with peft adapters from LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama_v1.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<s> [INST] Give me some python code to add the first five Fibonacci numbers. [/INST]\n",
      "   [/CONSTRAINT_FAILURE_NOTIFICATION]\n",
      "   [/*]\n",
      "   [CONSTRAINT_RULE]\n",
      "   [/*]\n",
      "   [CONSTRAINT_RULE]\n",
      "\n",
      "   [REST OF THE CONSTRAINT]\n",
      "\n",
      "   [END]\n",
      "\n",
      "But when it comes to enforcing the DDL constraints, i guess hibernate does not actually have that capability.\n",
      "Can anyone help on how to enforce the required constraints in a DDL fashion?\n",
      "Thanks in advance.\n",
      "EDIT\n",
      "I was not able to put the final picture of it working. In summary, hibernate enforcethis for me:\n",
      "\n",
      "\n",
      "EDIT1\n",
      "I added the data annotations to hibernate mappings. I am not sure the DDL part is now being executed correctly. I can update the data at anytime anyways... if there is any improvement to the above... please let me know. Thank you\n",
      "\n",
      "A: 1/ To check the constraint is having\n",
      "@Table(name = \"mytable\")\n",
      "   public class MyTable{\n",
      "\n",
      "   private String myId;\n",
      "   private String myId2;\n",
      "   private String\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation('base', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a29ba",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7326e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% if messages[0]['role'] != 'assistant' %}{{ bos_token }}{% endif %}{% for message in messages %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token }}{% endif %}{% endfor %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cc9ccf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59ac920076d49548616bdbcea099b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template:   0%|          | 0/43245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3093e73a681a4d12af2188592b11c5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepared with the help of code from: https://github.com/xfactlab/orpo/blob/main...\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "dataset_name = 'mlabonne/orpo-dpo-mix-40k' # Ensure this is defined\n",
    "\n",
    "max_num_samples = None # Set to None to use the full dataset\n",
    "# max_num_samples = 1000 # set to None to use the full dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "def build_dataset(tokenizer, data_name, cache_dir=None, max_num_samples=10000, test_split_max=1000):\n",
    "    # Determin the split specification based on max_num samples\n",
    "    split_spec = 'train' if max_num_samples is None else f'train[:{max_num_samples}]'\n",
    "\n",
    "    # Load the dataset\n",
    "    full_data = load_dataset(data_name, split=split_spec, cache_dir=cache_dir)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    if max_num_samples is not None:\n",
    "        full_data = full_data.shuffle(seed=42)\n",
    "    else:\n",
    "        full_data = full_data\n",
    "\n",
    "    # Determine the number of test samples\n",
    "    num_total_samples = len(full_data)\n",
    "    test_size = min(test_split_max, min(1000, int(0.1 * num_total_samples)))\n",
    "\n",
    "    # Randomly split the data into training and test sets\n",
    "    dataset = full_data.train_test_split(test_size=test_size)\n",
    "\n",
    "    # ds_train = dataset['train']\n",
    "    # ds_test = dataser['test']\n",
    "\n",
    "    column_names = list(dataset['train'].features)\n",
    "\n",
    "    def apply_dpo_template(example):\n",
    "        # function adapted from https://kaitchup.substrack.com/p/fine-tune-a-better-go\n",
    "        if all(k in example.keys() for k in ('chosen', 'rejected')):\n",
    "            # For DPO, the inputs are triples of (prompt, chosen, rejected), where 'chosen'\n",
    "            # We therefore need to extract the N-1 turns to form the prompt\n",
    "            prompt_messages = example['chosen'][:-1]\n",
    "            example['messages'] = example['chosen']\n",
    "\n",
    "            # Now we extract the final turn to define chosen/rejected responses\n",
    "            chosen_messages = example['chosen'][-1:]\n",
    "            rejected_messages = example['rejected'][-1:]\n",
    "            example['text_chosen'] = tokenizer.apply_chat_template(chosen_messages, tokenize=False)\n",
    "            example['text_rejected'] = tokenizer.apply_chat_template(rejected_messages, tokenize=False)\n",
    "            example['text_prompt'] = tokenizer.apply_chat_template(prompt_messages, tokenize=False)\n",
    "        return example\n",
    "\n",
    "    dataset = dataset.map(apply_dpo_template, remove_columns=column_names,\n",
    "                desc='Formatting comparisons with prompt template',)\n",
    "\n",
    "    for split in ['train', 'test']:\n",
    "        dataset[split] = dataset[split].rename_columns(\n",
    "            {'text_prompt': 'prompt', 'text_chosen': 'chosen', 'text_rejected': 'rejected', 'messages': 'messages'}\n",
    "        )\n",
    "\n",
    "    return dataset['train'], dataset['test']\n",
    "\n",
    "# Assuming 'tokenizer' and 'dataset_name' are already defined\n",
    "train, test = build_dataset(tokenizer, dataset_name, cache_dir='./dataset', max_num_samples=max_num_samples)\n",
    "\n",
    "# Check the chat template!!! <s> should not be included when tokenizing the respones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "080e9ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: <s>[INST] How can I use Python to randomly select a set number of tourist attractions in New York City from a given dataset? Additionally, can I add constraints such as selecting only those attractions within a certain distance or those that are open during specific hours? Please provide a sample code for this task. [/INST]\n",
      "\n",
      "\n",
      "Chosen: In this example, I'll assume you have a CSV file named \"attractions.csv\" with the following fields: \"name\", \"latitude\", \"longitude\", \"opening_time\", \"closing_time\". To achieve your goal, you can use Python with the help of libraries like pandas, random, and geopy. \n",
      "\n",
      "First, install the required libraries:\n",
      "\n",
      "```bash\n",
      "pip install pandas geopy\n",
      "```\n",
      "\n",
      "Sample Python code:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import random\n",
      "from geopy.distance import great_circle\n",
      "\n",
      "# Function for filtering attractions by hours\n",
      "def filter_by_hours(attractions, open_time, close_time):\n",
      "    open_time_filter = attractions['opening_time'] <= open_time\n",
      "    close_time_filter = attractions['closing_time'] >= close_time\n",
      "    return attractions[open_time_filter & close_time_filter]\n",
      "\n",
      "# Function for filtering attractions by distance\n",
      "def filter_by_distance(attractions, ref_location, max_distance):\n",
      "    filtered_attractions = []\n",
      "    for _, attraction in attractions.iterrows():\n",
      "        attraction_location = (attraction['latitude'], attraction['longitude'])\n",
      "        distance = great_circle(ref_location, attraction_location).miles\n",
      "        if distance <= max_distance:\n",
      "            filtered_attractions.append(attraction)\n",
      "\n",
      "    return pd.DataFrame(filtered_attractions)\n",
      "\n",
      "# Load the dataset\n",
      "data = pd.read_csv(\"attractions.csv\")\n",
      "\n",
      "# Filter by hours\n",
      "filtered_by_hours_data = filter_by_hours(data, open_time='10:00', close_time='18:00')\n",
      "\n",
      "# Filter by distance\n",
      "reference_location = (40.7128, -74.0060)  # NYC coordinates\n",
      "max_distance = 5  # miles\n",
      "filtered_attractions = filter_by_distance(filtered_by_hours_data, ref_location=reference_location, max_distance=max_distance)\n",
      "\n",
      "# Randomly select attractions\n",
      "number_of_attractions = 3\n",
      "random_selection = filtered_attractions.sample(number_of_attractions)\n",
      "\n",
      "# Print the selected attractions\n",
      "print(\"Randomly selected tourist attractions:\")\n",
      "for index, attraction in random_selection.iterrows():\n",
      "    print(f\"{attraction['name']} - Opening Time: {attraction['opening_time']} - Closing Time: {attraction['closing_time']}\")\n",
      "```\n",
      "\n",
      "This sample code demonstrates how to filter the dataset by opening and closing hours and distance from a reference location. You need to modify the field names and sample dataset, and modify the functions if necessary as per your actual dataset.\n",
      "\n",
      "Make sure to update `reference_location`, `max_distance`, `open_time`, and `close_time` based on your desired constraints and replace the \"attractions.csv\" filename with the actual file path.</s>\n",
      "\n",
      "\n",
      "Rejected: Sure, you can use Python and a few libraries to accomplish this. Here’s a simple way to do it using pandas, numpy, and the geopy library (assuming the data for the tourist attractions is stored in a CSV file). \n",
      "\n",
      "First, you need to install the required libraries, if you haven’t already. You can do this using pip:\n",
      "\n",
      "```python\n",
      "pip install pandas numpy geopy\n",
      "```\n",
      "\n",
      "Let's assume you have a dataframe that contains the necessary information about the tourist attractions in New York City. Here is a sample code:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from geopy.distance import geodesic\n",
      "\n",
      "# Load the data\n",
      "df = pd.read_csv('tourist_attractions.csv')\n",
      "\n",
      "# Define the number of random attractions you want to select\n",
      "num_attractions = 5\n",
      "\n",
      "# Define the latitude and longitude of New York City\n",
      "lat = 40.7128\n",
      "lng = -74.0060\n",
      "\n",
      "# Assume default distance criteria\n",
      "default_distance = 5000  # 5km\n",
      "\n",
      "# Assume default working hours (you may need to adjust to match data)\n",
      "default_open = pd.to_datetime('09:00')\n",
      "default_close = pd.to_datetime('19:00')\n",
      "\n",
      "# Convert hours to timedelta\n",
      "default_open_td = pd.Timedelta(default_open)\n",
      "default_close_td = pd.Timedelta(default_close)\n",
      "\n",
      "# Define the distance function\n",
      "def calculate_distance(lat1, lon1, lat2, lon2):\n",
      "    distance = geodesic(lat1, lon1, lat2, lon2).km\n",
      "    return distance\n",
      "\n",
      "# Define the is_open function\n",
      "def is_open(open_time, close_time):\n",
      "    now = pd.Timestamp(dt=datetime.now().time())\n",
      "    open_time_td = pd.Timedelta(open_time)\n",
      "    close_time_td = pd.Timedelta(close_time)\n",
      "    if open_time_td <= now <= close_time_td:\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "# Filter the dataframe based on distance and working hours\n",
      "df_filtered = df[(calculate_distance(lat, df['lat'], lng, df['lng']) <= default_distance) & \n",
      "                (is_open(default_open_td, default_close_td) == True)]\n",
      "\n",
      "# Randomly select a certain number of attractions\n",
      "random_attractions = np.random.choice(df_filtered.index, size=num_attractions, replace=False)\n",
      "\n",
      "# Print out the selected attractions\n",
      "for i in random_attractions:\n",
      "    print(df_filtered.loc[i])\n",
      "```\n",
      "\n",
      "In this code, I'm using the geopy library to calculate the geodesic distance between a given latitude and longitude (the center of New York City) and every latitude and longitude in the dataset. Those within a certain distance are then further filtered based on whether the attractions are open at the current time. Finally, a random sample of attractions within these filters is selected.\n",
      "\n",
      "Please note that you will need to adjust this code according to your specific dataset and business rules. For instance, the method of calculating distance, the definition of working hours, the random sampling method, etc. might all need to be adjusted based on your specific needs. \n",
      "\n",
      "Also, it's important to note that this code doesn't include error handling. You might want to add some error handling and also make the code more efficient if the dataset is very large.</s>\n",
      "\n",
      "\n",
      "Messages (incl. prompt): [{'content': 'How can I use Python to randomly select a set number of tourist attractions in New York City from a given dataset? Additionally, can I add constraints such as selecting only those attractions within a certain distance or those that are open during specific hours? Please provide a sample code for this task.', 'role': 'user'}, {'content': 'In this example, I\\'ll assume you have a CSV file named \"attractions.csv\" with the following fields: \"name\", \"latitude\", \"longitude\", \"opening_time\", \"closing_time\". To achieve your goal, you can use Python with the help of libraries like pandas, random, and geopy. \\n\\nFirst, install the required libraries:\\n\\n```bash\\npip install pandas geopy\\n```\\n\\nSample Python code:\\n\\n```python\\nimport pandas as pd\\nimport random\\nfrom geopy.distance import great_circle\\n\\n# Function for filtering attractions by hours\\ndef filter_by_hours(attractions, open_time, close_time):\\n    open_time_filter = attractions[\\'opening_time\\'] <= open_time\\n    close_time_filter = attractions[\\'closing_time\\'] >= close_time\\n    return attractions[open_time_filter & close_time_filter]\\n\\n# Function for filtering attractions by distance\\ndef filter_by_distance(attractions, ref_location, max_distance):\\n    filtered_attractions = []\\n    for _, attraction in attractions.iterrows():\\n        attraction_location = (attraction[\\'latitude\\'], attraction[\\'longitude\\'])\\n        distance = great_circle(ref_location, attraction_location).miles\\n        if distance <= max_distance:\\n            filtered_attractions.append(attraction)\\n\\n    return pd.DataFrame(filtered_attractions)\\n\\n# Load the dataset\\ndata = pd.read_csv(\"attractions.csv\")\\n\\n# Filter by hours\\nfiltered_by_hours_data = filter_by_hours(data, open_time=\\'10:00\\', close_time=\\'18:00\\')\\n\\n# Filter by distance\\nreference_location = (40.7128, -74.0060)  # NYC coordinates\\nmax_distance = 5  # miles\\nfiltered_attractions = filter_by_distance(filtered_by_hours_data, ref_location=reference_location, max_distance=max_distance)\\n\\n# Randomly select attractions\\nnumber_of_attractions = 3\\nrandom_selection = filtered_attractions.sample(number_of_attractions)\\n\\n# Print the selected attractions\\nprint(\"Randomly selected tourist attractions:\")\\nfor index, attraction in random_selection.iterrows():\\n    print(f\"{attraction[\\'name\\']} - Opening Time: {attraction[\\'opening_time\\']} - Closing Time: {attraction[\\'closing_time\\']}\")\\n```\\n\\nThis sample code demonstrates how to filter the dataset by opening and closing hours and distance from a reference location. You need to modify the field names and sample dataset, and modify the functions if necessary as per your actual dataset.\\n\\nMake sure to update `reference_location`, `max_distance`, `open_time`, and `close_time` based on your desired constraints and replace the \"attractions.csv\" filename with the actual file path.', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print('Prompt:', train['prompt'][0])\n",
    "print('\\n\\nChosen:', train['chosen'][0])\n",
    "print('\\n\\nRejected:', train['rejected'][0])\n",
    "print('\\n\\nMessages (incl. prompt):', train['messages'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1aa365",
   "metadata": {},
   "source": [
    "# Train!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea2228",
   "metadata": {},
   "source": [
    "## Set up and run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f37081e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO\n"
     ]
    }
   ],
   "source": [
    "model_name = model_id.split('/')[-1]\n",
    "\n",
    "epochs=1\n",
    "grad_accum=4\n",
    "batch_size=8\n",
    "fine_tune_tag='ORPO'\n",
    "save_dir = f'./results/{model_name}_{dataset_name}_{epochs}_epochs_{fine_tune_tag}'\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2387e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Custom callback to log metrics\n",
    "class LoggingCallback(transformers.TrainerCallback):\n",
    "    def __init__(self, log_file_path):\n",
    "        self.log_file_path = log_file_path\n",
    "\n",
    "    def on_log(self, args, state, control, model=None, logs=None, **kwargs):\n",
    "        with open(self.log_file_path, 'a') as f:\n",
    "            if 'loss' in logs:\n",
    "                f.write(f'Step: {state.global_step}, Training Loss: {logs[\"loss\"]}\\n')\n",
    "                if 'eval_loss' in logs:\n",
    "                    f.write(f'Step: {state.global_step}, Eval Loss: {logs[\"eval_loss\"]}\\n')\n",
    "                f.flush()  # Force flush the buffered data to file\n",
    "\n",
    "        # Check if the current step is a checkpoint step\n",
    "        if state.global_step % int(args.save_steps) == 0:\n",
    "            # Check if the last checkpoint path exists\n",
    "            if state.best_model_checkpoint:\n",
    "                checkpoint_dir = state.best_model_checkpoint\n",
    "            else:\n",
    "                # If not, construct the checkpoint directory path\n",
    "                checkpoint_dir = os.path.join(args.output_dir, f'checkpoint-{state.global_step}')\n",
    "\n",
    "            # Ensure the checkpoint directory exists\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "            # Save trainable params in the checkpoint directory\n",
    "            current_trainable_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "            current_trainable_params_state_dict = {n: p.data for n, p in current_trainable_params.items()}\n",
    "            file_path = os.path.join(checkpoint_dir, 'trainable_params.pt')\n",
    "            torch.save(current_trainable_params_state_dict, file_path)\n",
    "\n",
    "# Log file path\n",
    "cache_dir = './dataset'  # Assuming cache_dir is defined elsewhere in your code\n",
    "log_file_path = os.path.join(cache_dir, 'training_logs.txt')\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "logging_callback = LoggingCallback(log_file_path)\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b433c5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ORPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2750a0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df051585b979467aae7d9e877076de0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83aab6aa5633456dbe2e4f5668b73943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "from trl import ORPOTrainer, ORPOConfig\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "orpo_config = ORPOConfig(\n",
    "    beta=0.2, # the lambda/alpha hyperparamter in the paper/code (0.5 is recommended for small mdoels 1B, 0.1/0.2 for larger models)\n",
    "    #max_steps=160, # comment this out after the first time you ...\n",
    "    save_steps=80, ### MAKE SURE TO CHECK THIS VALUE IS GOOD FOR\n",
    "    logging_steps=1,\n",
    "    num_train_epochs=epochs,\n",
    "    output_dir=save_dir,\n",
    "    eval_strategy='steps', # or 'epoch'\n",
    "    do_eval=True,\n",
    "    eval_steps=0.2,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=grad_accum,\n",
    "    log_level='debug',\n",
    "    #optim='paged_adamw_8bit',\n",
    "    #fp16=True, # For non-Ampere GPUs\n",
    "    bf16=True, # For Ampere GPUs or later\n",
    "    max_grad_norm=0.3,\n",
    "    lr_scheduler_type='linear',\n",
    "    #hub_private_repo=True,\n",
    "    warmup_ratio=0.03, # optional, may help stability at the start (learning rate is ower for the first stepts)\n",
    "    optim='adamw_torch', # comment out for LoRA +\n",
    "    learning_rate=1e-4, # comment out for LoRA +\n",
    "\n",
    "    max_prompt_length=512,\n",
    "    max_length=1024,\n",
    "\n",
    "    max_completion_length=1024,\n",
    "    remove_unused_columns=False,\n",
    "    #gradient_checkpoint=True,\n",
    "    #gradient_checkpointing_kwargs={'use_reentrant': True},\n",
    "\n",
    "    report_to='wandb',\n",
    "    )\n",
    "\n",
    "orpo_trainer = ORPOTrainer(\n",
    "    model,\n",
    "    args=orpo_config,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    peft_config=peft_config, # comment out if passing a peft model\n",
    "    callbacks=[logging_callback] # Add custom callback here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1587ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 8\n",
      "***** Running training *****\n",
      "  Num examples = 43,245\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1,351\n",
      "  Number of trainable parameters = 6,580,224\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/_LEARNING/me/FineTuning/wandb/run-20240611_165601-gbjdl9nu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/demaz/huggingface/runs/gbjdl9nu' target=\"_blank\">./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO</a></strong> to <a href='https://wandb.ai/demaz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/demaz/huggingface' target=\"_blank\">https://wandb.ai/demaz/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/demaz/huggingface/runs/gbjdl9nu' target=\"_blank\">https://wandb.ai/demaz/huggingface/runs/gbjdl9nu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1351' max='1351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1351/1351 2:24:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Nll Loss</th>\n",
       "      <th>Log Odds Ratio</th>\n",
       "      <th>Log Odds Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>1.507100</td>\n",
       "      <td>1.381568</td>\n",
       "      <td>52.669400</td>\n",
       "      <td>18.986000</td>\n",
       "      <td>2.373000</td>\n",
       "      <td>-0.218683</td>\n",
       "      <td>-0.362576</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>0.143893</td>\n",
       "      <td>-1.812878</td>\n",
       "      <td>-1.093413</td>\n",
       "      <td>-1.476253</td>\n",
       "      <td>-1.717713</td>\n",
       "      <td>1.269838</td>\n",
       "      <td>-0.558649</td>\n",
       "      <td>0.867475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542</td>\n",
       "      <td>1.449500</td>\n",
       "      <td>1.358151</td>\n",
       "      <td>52.145100</td>\n",
       "      <td>19.177000</td>\n",
       "      <td>2.397000</td>\n",
       "      <td>-0.214824</td>\n",
       "      <td>-0.416862</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.202038</td>\n",
       "      <td>-2.084310</td>\n",
       "      <td>-1.074121</td>\n",
       "      <td>-1.408604</td>\n",
       "      <td>-1.653109</td>\n",
       "      <td>1.249467</td>\n",
       "      <td>-0.543421</td>\n",
       "      <td>1.174083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>813</td>\n",
       "      <td>1.372000</td>\n",
       "      <td>1.346881</td>\n",
       "      <td>52.070800</td>\n",
       "      <td>19.205000</td>\n",
       "      <td>2.401000</td>\n",
       "      <td>-0.213782</td>\n",
       "      <td>-0.456337</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.242554</td>\n",
       "      <td>-2.281683</td>\n",
       "      <td>-1.068911</td>\n",
       "      <td>-1.383019</td>\n",
       "      <td>-1.628821</td>\n",
       "      <td>1.241521</td>\n",
       "      <td>-0.526801</td>\n",
       "      <td>1.392350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1084</td>\n",
       "      <td>1.365200</td>\n",
       "      <td>1.342407</td>\n",
       "      <td>52.153100</td>\n",
       "      <td>19.174000</td>\n",
       "      <td>2.397000</td>\n",
       "      <td>-0.213112</td>\n",
       "      <td>-0.449513</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.236401</td>\n",
       "      <td>-2.247566</td>\n",
       "      <td>-1.065561</td>\n",
       "      <td>-1.378303</td>\n",
       "      <td>-1.618303</td>\n",
       "      <td>1.236165</td>\n",
       "      <td>-0.531211</td>\n",
       "      <td>1.362422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-80\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-80/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-80/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-160\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-160/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-160/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-240\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-240/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-240/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-320\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-320/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-320/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-400\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-400/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-480\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-480/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-480/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-560\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-560/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-560/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-640\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-640/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-640/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-720\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-720/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-720/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-800\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-800/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-880\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-880/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-880/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-960\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-960/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-960/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1040\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1040/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1040/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1120\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1120/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1120/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1200\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1200/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1280\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1280/tokenizer_config.json\n",
      "Special tokens file saved in ./results/TinyLlama_v1.1_mlabonne/orpo-dpo-mix-40k_1_epochs_ORPO/checkpoint-1280/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1351, training_loss=1.381516691757784, metrics={'train_runtime': 8655.4139, 'train_samples_per_second': 4.996, 'train_steps_per_second': 0.156, 'total_flos': 0.0, 'train_loss': 1.381516691757784, 'epoch': 0.9996300406955235})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False # silence the warnings\n",
    "orpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d6d6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to llmat/TinyLlama-1.1B_ORPO_small\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "tokenizer config file saved in llmat/TinyLlama-1.1B_ORPO_small/tokenizer_config.json\n",
      "Special tokens file saved in llmat/TinyLlama-1.1B_ORPO_small/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "orpo_trainer.save_model(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b072925",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45d75303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to hold training and evaluation losses and steps\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "train_steps = []\n",
    "eval_steps = []\n",
    "\n",
    "# Populate the lists from the log history\n",
    "for entry in orpo_trainer.state.log_history:\n",
    "    if 'loss' in entry:\n",
    "        train_losses.append(entry['loss'])\n",
    "        train_steps.append(entry['step'])\n",
    "    if 'eval_loss' in entry:\n",
    "        eval_losses.append(entry['eval_loss'])\n",
    "        eval_steps.append(entry['step'])\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(train_steps, train_losses, label='Train Loss')\n",
    "plt.plot(eval_steps, eval_losses, label='Eval Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1992fd6",
   "metadata": {},
   "source": [
    "## Save trainable params if training non-LoRA modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "194e8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dictionary to reflect the final state of the model's\n",
    "trainable_params_state_dict = {n: p.data for n, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "# Save the final state of the trainable parameters (ONLY RELEVANT FOR NON-LORA ADAPTERS)\n",
    "final_save_path = os.path.join(save_dir, 'trainable_params_final.pt')\n",
    "torch.save(trainable_params_state_dict, final_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74324c1b",
   "metadata": {},
   "source": [
    "# Evaluate after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d196921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can set to true for faster inference\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bcc48e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding to inference with peft adapters from LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama_v1.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<s> [INST] What is one plus one? "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/INST]One plus one equals two.</s>\n",
      "\n",
      "\n",
      "\n",
      "Proceeding to inference with peft adapters from LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama_v1.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<s> [INST] Give me some python code to add the first five Fibonacci numbers. [/INST]Here is a simple Python code that can add the first five Fibonacci numbers:\n",
      "```python\n",
      "F = [0, 1, 1, 2, 3, 5]\n",
      "for i in range(1, 10):\n",
      "   print(F[i] + F[i - 1])\n",
      "```\n",
      "This program first defines an array of five elements `F` and goes through that list `F`, adding up the first elements using the `+` operator. Once you add the first element to the list, the iterator moves on to the second element in the list, the first of the two next elements, and then the second element, etc. until you reach the tenth element (10 in this case).\n",
      "\n",
      "This program outputs:\n",
      "\n",
      "```\n",
      "0 + 1 = 1\n",
      "1 + 1 = 2\n",
      "2 + 2 = 3\n",
      "3 + 3 = 6\n",
      "4 + 6 = 10\n",
      "```\n",
      "\n",
      "The Python language is case-sensitive, so you need to use lowercase `i` to refer to the iterator. The range function can be an alias for the `range` module to\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation('base', tokenizer) # use this if training was done with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31d0ad",
   "metadata": {},
   "source": [
    "# Merge Adapters and Save Model to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f331edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "del orpo_trainer, model\n",
    "gc.collect()\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU cache cleared\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU cache to clear.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c65b4bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file TinyLlama/TinyLlama_v1.1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"TinyLlama/TinyLlama_v1.1\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file TinyLlama/TinyLlama_v1.1/pytorch_model.bin\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama_v1.1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file TinyLlama/TinyLlama_v1.1/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 2048,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reload tokenizer and model\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Merge adapter with base model\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c520f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token $HUGGINGFACE_TOKEN --add-to-git-credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47354ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the save and push paths\n",
    "adapter_model = f\"llmat/{model_name}-{fine_tune_tag}-adapters\"\n",
    "new_model = f\"llmat/{model_name}-{fine_tune_tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06b8643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in llmat/TinyLlama_v1.1-ORPO-adapters/tokenizer_config.json\n",
      "Special tokens file saved in llmat/TinyLlama_v1.1-ORPO-adapters/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('llmat/TinyLlama_v1.1-ORPO-adapters/tokenizer_config.json',\n",
       " 'llmat/TinyLlama_v1.1-ORPO-adapters/special_tokens_map.json',\n",
       " 'llmat/TinyLlama_v1.1-ORPO-adapters/tokenizer.model',\n",
       " 'llmat/TinyLlama_v1.1-ORPO-adapters/added_tokens.json',\n",
       " 'llmat/TinyLlama_v1.1-ORPO-adapters/tokenizer.json')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(adapter_model, push_to_hub=True, use_auth_token=True)\n",
    "\n",
    "# Save the tokenizer to make sure the updated config is saved as well\n",
    "tokenizer.save_pretrained(adapter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "590e146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:836: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Configuration saved in /tmp/tmp7lo8pkt5/config.json\n",
      "Configuration saved in /tmp/tmp7lo8pkt5/generation_config.json\n",
      "Model weights saved in /tmp/tmp7lo8pkt5/model.safetensors\n",
      "Uploading the following files to llmat/TinyLlama_v1.1-ORPO: README.md,generation_config.json,model.safetensors,config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4f3a1d4ca54d5c977a6c0c3f6e148d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/llmat/TinyLlama_v1.1-ORPO/commit/b783e88b9a2fea1f89a705bf08779be127f6307a', commit_message='Upload LlamaForCausalLM', commit_description='', oid='b783e88b9a2fea1f89a705bf08779be127f6307a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(new_model, use_auth_token=True, max_shard_size='10GB', use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6933513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:836: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "tokenizer config file saved in /tmp/tmp8h8iicon/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmp8h8iicon/special_tokens_map.json\n",
      "Uploading the following files to llmat/TinyLlama_v1.1-ORPO: tokenizer.json,tokenizer_config.json,README.md,special_tokens_map.json,tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "# Push the tokenizer\n",
    "## OR Reload from scratch if you don't want pad tokens to be in the tokenizer\n",
    "\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.push_to_hub(new_model, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68db42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
